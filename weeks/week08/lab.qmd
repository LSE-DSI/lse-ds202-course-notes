---
title: "ðŸ’» Week 08 - Lab Roadmap (90 min)"
date: 14 November 2022
date-meta: 14 November 2022
from: markdown+emoji
server: shiny
author: Dr. Stuart Bramwell/Dr. Jon Cardoso-Silva
---

**Context**

This lab session draws on [:spiral_calendar: Week 04 lecture/workshop](/weeks/week04/lecture.qmd) and [:spiral_calendar: Week 05 lecture](/weeks/week05/lecture.qmd) content.

It also reuses elements of **tidymodels** introduced in previous labs where we used functions from `library(broom)` or `library(rsample)`. These packages are part of `tidymodels`. For the record, tidymodel's ['Get Started' tutorials](https://www.tidymodels.org/start/) are really good.

:::{.callout-important}
Download this page as an RMarkdown file from Moodle.
:::

**Topics**

More specifically, these are the things we will explore or revisit:

-   Difference between Classification vs Regression ([:spiral_calendar: Week 03 lecture](/weeks/week03/lecture.qmd))
-   [k-fold cross-validation](/weeks/week04/lecture.html#the-cross-validation-setup)
-   [Support Vector Machine (SVM)](/weeks/week05/lecture.html#part-ii---non-linear-algorithms-support-vector-machines-45-50-min)
-   Hyperparameters

<details><summary>**Setup**</summary>

## Setup

:bulb: *Some of you have mentioned that your R version cannot handle tidymodels. We recommend you update R to version 4.2.0 or above.*

**Packages you will need**

```{r, message=FALSE, warning=FALSE, echo=TRUE}
library('ISLR2')       # for the data
library('tidyverse')   # to use things like the pipe (%>%)
library('e1071')       # for SVM model
library('tidymodels')  # for model tuning, cross-validation etc.

# Vanity packages:
library('GGally')      # for pretty correlation plot
library('ggsci')       # for pretty plot colours
library('cvms')        # for pretty confusion matrix plots
```

</details>

<details><summary>The Data (10 min)</summary>

## The Data (10 min)

### :tangerine:Orange Juice

This week we will use a different ISLR2 dataset: `OJ` . We will perform a **classification** task with the goal to predict the `Purchase` column.

> *The data contains 1070 **purchases** where the customer either purchased Citrus Hill or Minute Maid Orange Juice. A number of characteristics of the customer and product are recorded.*

```{r}
ISLR2::OJ %>% head()
```

To understand what each variable represent, open the R Console, type the following and hit ENTER:

``` r
?ISLR2::OJ
```

**Which variables can help us distinguish the two different brands?**

To simplify our plots later on, let's focus on just two predictors:

```{r, message=FALSE, dpi=300}
plot_df <- ISLR2::OJ %>% select(Purchase, LoyalCH, PriceDiff)

g = (
  ggpairs(plot_df, aes(colour=Purchase))
  
  # Customizing the plot
  + scale_colour_startrek()
  + scale_fill_startrek()
  + theme_bw()
)
g 
```

## :chart_with_upwards_trend: Stock Market

We will also use the `Smarket` dataset from the ISLR2 package. We will perform a **regression** task with the goal to predict the percentage of return of the S&P 500 stock index on any given day, as represented by the `Today` column.

> *Daily percentage returns for the S&P 500 stock index between 2001 and 2005.*

```{r}
ISLR2::Smarket %>% head()
```

```{r, message=FALSE, dpi=300}
plot_df <- ISLR2::Smarket %>% select(Today, Volume, Lag1, Lag2)

g = (
  ggpairs(plot_df)
  
  # Customizing the plot
  + scale_colour_startrek()
  + scale_fill_startrek()
  + theme_bw()
)
g 
```

To understand what each variable represent, open the R Console, type the following and hit ENTER:

``` r
?ISLR2::Smarket
```
</details>

<details><summary>Step 1: SVM models for classification (30 min)</summary>

## Step 1: SVM models for classification  (30 min)

SVM stands for **S**upport **V**ector **M**achines. Revisit [:spiral_calendar: Week 05 lecture](/weeks/week05/lecture.qmd) or Chapter 9 of our textbook to understand more about this algorithm.

R does not come with SVM, so we need to import it from a library. Let's start with the function `svm` we used in the Week 05 lecture, imported from the [`e1071` package](https://cran.r-project.org/web/packages/e1071/e1071.pdf). Here are a few things to know about the `svm` function:

-   The `svm` command is largely similar to other commands such as `lm` and `glm` in that the first parameter is an [R formula](https://www.datacamp.com/tutorial/r-formula-tutorial) and the second is the data set.
-   There are a few other options, but we will focus on specifying a radial kernel using `kernel = 'radial'`.
-   We *can* specify the type of machine learning task we are performing. Since we are doing classification, we use the option `type = 'C-classification'`.

### Step 1.1: Train a SVM model

```{r}
filtered_data <- ISLR2::OJ %>% select(Purchase, LoyalCH, PriceDiff)

orange_svm_model <- svm(Purchase ~ .,
                        data=filtered_data,
                        kernel='radial', 
                        type='C-classification')
orange_svm_model
```

:dart: **ACTION POINT**: What does the 'Number of Support Vectors' represent?

> your text here

:dart: **ACTION POINT**: What would happened if we changed `kernel` to `kernel="linear"`?

> your text here

### Step 1.2: Goodness-of-Fit of the SVM

Let's investigate how well our model fits the data. Let's reuse the model we trained (`orange_svm_model`) and predict the *same samples* we used to train it. To avoid modifying our original dataframe, let's save the output of the prediction in an auxiliary df (`plot_df`):

```{r, output=FALSE}
plot_df <- 
    filtered_data %>% 
    mutate(class_pred = predict(orange_svm_model, newdata = .))
head(plot_df)
```

**Add a `is_correct` column** to indicate whether the prediction was correct or not:

```{r}
plot_df <- plot_df %>% mutate(is_correct = class_pred == Purchase)
head(plot_df)
```

Remember what we did in the Decision Tree example last week!

#### Simple confusion matrix:

```{r, output=FALSE}
confusion_matrix <- 
    table(expected=plot_df$Purchase, class_pred=plot_df$class_pred)
print(confusion_matrix)
```

#### Nicer looking confusion matrix:

```{r, output=FALSE, message=FALSE}
plot_confusion_matrix(as_tibble(confusion_matrix), 
                      target_col = "expected", 
                      prediction_col = "class_pred",
                      
                      # Customizing the plot
                      add_normalized = TRUE,
                      add_col_percentages = FALSE,
                      add_row_percentages = FALSE,
                      counts_col = "n",
                      )
```

:dart: **ACTION POINT**: How well does the model fit the data? What is your opinion?

#### Measure: Precision

Remember from Week 04 Lecture/Workshop (notebook can be found under:inbox_tray:W04 Lecture Files on Moodle):

> **PRECISION:** Given all predictions for a specific class, how many were True Positives? In other words, Precision = True Positives/(True Positives + False Positives).

Let's calculate the score for the CH class. That is, as if CH="Yes" and MM="No".

```{r}
# expected == CH & predicted == CH
total_correct_CH   <- confusion_matrix["CH", "CH"]  

# sum of samples predicted == CH
total_predicted_CH <- sum(confusion_matrix[, "CH"]) 

precision          <- total_correct_CH/total_predicted_CH
cat(sprintf("%.2f%%", 100*precision))
```

#### Measure: Recall

> Also called True Positive Rate = True Positive/(True Positives + False Negatives)

```{r}
# number of samples of brand CH
total_real_CH      <- sum(confusion_matrix["CH", ]) 

recall <- total_correct_CH/total_real_CH
cat(sprintf("%.2f%%", 100*recall))
```

#### Measure: F1-SCORE

> **F1-SCORE:** A combination of Precision and Recall
>
> $$
> \operatorname{F1-score} = \frac{2 \times \operatorname{Precision} \times \operatorname{Recall}}{(\operatorname{Precision} + \operatorname{Recall})}
> $$

```{r}
f1_score <- (2*precision*recall)/(precision + recall)

cat(f1_score)
```

### Step 1.3: Visualize the SVM decision space

Here we will demonstrate how you could simulate some data to cover the entire feature space of the data we are modelling. What do we mean by that? By inspecting `LoyalCH` and `PriceDiff`, we see the range values these variables can assume:

```{r}
filtered_data %>% 
    select(c(LoyalCH, PriceDiff)) %>%
    summary()
```

:bulb: We can simulate data to account for all possible combinations of `LoyalCH` and `PriceDiff`. We achieve this using `crossing`, another `tidyverse` function:

-   We feed `crossing` a sequence of numbers that range from the minimal and maximal values of both variables, incremented by 0.1 values.
-   We then create a new variable `class_pred` which uses the SVM model object to predict the brand of orange juice purchased by the customer
-   Note that we say `newdata = .` to indicate that we simply want to use the data set created with `crossing` as our new data.

```{r}
sim.data <- 
  crossing(LoyalCH   = seq(0,1,0.05),
           PriceDiff = seq(-1,1,0.1)) %>% 
  mutate(class_pred = predict(orange_svm_model, newdata = .))
head(sim.data)
```

The data above is all synthetic ("fake")! But it is very useful to colour the background of our plot.

We use `geom_tile` to show the area the SVM model identifies as Chinstrap penguins. We then use `geom_point` to overlay the actual data. Red dots in blue areas and vice versa indicate cases where the SVM model makes errors.

```{r, dpi=300}

g <- (
  plot_df %>%   
    ggplot()
  
    # Tile the background of the plot with SVM predictions
    + geom_tile(data = sim.data, aes(x=LoyalCH, y=PriceDiff, fill = class_pred), alpha = 0.25)
  
    # Actual data
    + geom_point(aes(x=LoyalCH, y=PriceDiff, colour = Purchase, shape = is_correct), size=2.5, stroke=0.95, alpha=0.7)
  
    # Define X and Os
    + scale_shape_manual(values = c(4, 1))
    
    # (OPTIONAL) Customizing the colours and theme of the plot
    + scale_x_continuous(labels=scales::percent)
    + scale_colour_startrek()
    + scale_fill_startrek()
    + theme_minimal()
    + theme(panel.grid = element_blank(), legend.position = 'bottom', plot.title = element_text(hjust = 0.5))
    + labs(x = 'Customer brand loyalty for CH', y = 'Sale price of MM less sale price of CH', fill = 'Brand', colour = 'Brand', shape = 'Correct prediction?', title = sprintf('Overall Training Accuracy = %.2f %%', 100*(sum(plot_df$correct)/nrow(plot_df))))
)

g
```

:handshake: **WORKING TOGETHER** In pairs, discuss what you see in the plot:

-   What do the shape of dots represent? The `X` and `O`s?

> your text here

-   What do the colours of the dots represent?

> your text here

-   What do the background colour in the plot represent?

> your text here

-   Can you point in the plot roughly which dots you would expect to be the support vectors?

</details>

<details><summary>Step 2: Doing the same with `tidymodels` (20 min)</summary>

## Step 2: Doing the same with `tidymodels` (20 min)

The function `svm` from `library(e1071)` package is not the only way to run SVM in R. The package `parsnip` also have its own SVM functions. The functionality is roughly the same but there are differences in how you write the code.

*`parsnip` already comes installed in `tidymodels`, so we do not need to import or install anything else.*

### Step 2.1 Training the SVM model

We specify a **radial basis function** SVM (see the part about kernels in the [:spiral_calendar: Week 05 lecture](/weeks/week05/lecture.qmd)) with the function `svm_rbf`.

In the spirit of `tidyverse`, we pipe the SVM algorithm into the `fit` function, where we can define the R formula like we have been doing with other algorithms:

```{r}

orange_tidymodel <-
  svm_rbf() %>% 
  set_mode('classification') %>% 
  fit(Purchase ~ ., data = filtered_data)

orange_tidymodel
```

:dart: **ACTION POINT**: Compare the output above to that of another colleague. Why don't you get the exact same output?

> your personal notes go here

:bulb: If you want to try different kernels, you will need to replace `svm_rbf()` by `svm_linear()` or `svm_poly()`.

### Step 2.2: Goodness-of-Fit of the SVM

Let's investigate how well our model fits the data. Let's reuse the model we trained (`orange_tidymodel`) and predict the *same samples* we used to train it.

Function `augment(<model>, <df>)` of `tidymodels` applies a model to a dataframe and return the same data plus a few columns:

```{r, output=FALSE}
plot_df <- augment(orange_tidymodel, filtered_data)
head(plot_df)
```

:dart: **ACTION POINT**: How is the `plot_df` data frame above different to the first plot_df we created in **Step 1.2**?

> your notes go here

**Add a `is_correct` column** to indicate whether the prediction was correct or not:

```{r}
plot_df <- plot_df %>% mutate(is_correct = .pred_class == Purchase)
head(plot_df)
```

#### Measure: Precision

You don't need to calculate precision by hand, just use the `precision()` function from tidymodels:

```{r}
plot_df %>% precision(Purchase, .pred_class) %>% head()
```

#### Measure: Recall

You don't need to calculate recall by hand, just use the `recall()` function from tidymodels:

```{r}
plot_df %>% recall(Purchase, .pred_class) %>% head()
```

#### Measure: F1-score

You don't need to calculate F1-score by hand, just use the `f_meas()` function from tidymodels:

```{r}
plot_df %>% f_meas(Purchase, .pred_class) %>% head()
```

#### (Optional) ROC curve

Plot the ROC curve for class `Purchase=="CH"` :

```{r}
plot_df %>% 
  roc_curve(Purchase, .pred_CH) %>% 
  autoplot
```

#### :house: **Take-home exercise Q1:**

Edit the cell below modifying `event_level` from `"second"` to `"first"`. Why do you get different results? What do you think is going on?

``` r
plot_df %>% f_meas(Purchase, .pred_class, event_level=...)
```

:bulb:Tip: Read the documentation of `f_meas` to understand what `event_level` represents. (Type `?f_meas`)

:bulb: **Gold** **Tip**: note the **Levels** of the `factor` variable called `Purchase`:

``` r
plot_df$Purchase
```

#### :house: **Take-home exercise Q2:**

Create a plot of the confusion matrix for the `orange_tidymodel` like we did in Step 1.

```{r}

## your code goes here
```

#### :house: **Take-home exercise Q3:**

Create a plot of SVM decision space for the `orange_tidymodel` like we did in Step 1.

```{r}

## your code goes here
```

:dart: **ACTION POINT**: If you were to run the SVM algorithm by yourself in another dataset, which version would you prefer, the one in Step 1 or the one in Step 2?

> your notes go here

</details>

<details><summary>Step 3: What about regression? (30 min)</summary>

## Step 3: What about regression? (30 min)

Here we will be using the :chart_with_upwards_trend: `SMarket` data.

### Step 3.1: Train the model

Let's select just the predictors `Volume` and `Lag1` and fit a regression model to predict `Today`:

```{r}
# Remove Direction, otherwise we would be "cheating" 
filtered_data <- ISLR2::Smarket %>% select(Today, Volume, Lag1)

smarket_tidymodel <-
  svm_rbf() %>% 
  set_mode('regression') %>% 
  fit(Today ~ ., data = filtered_data)

smarket_tidymodel
```

### Step 3.2: Goodness-of-Fit of the SVM

Since the target variable is continuous, not discrete, we cannot plot confusion matrix nor anything like that. We will have to go back to the idea of residuals ([:spiral_calendar: Week 02 Lecture](/weeks/week02/lecture.html) & [:computer: Week 03 - Lab](/weeks/week03/lab.html)).

```{r}
plot_df <- 
  augment(smarket_tidymodel, filtered_data) %>% 
  mutate(row_number=row_number()) # adding this here just to make our plot easier
plot_df %>% head()
```

:dart: **ACTION POINT**: What do the different columns mean?

> your text go here

Now, let's look at the distribution of residuals and let's mark the absolute residuals above 2 to flag the worst predictions (2 was an arbitrary choice, it all depends on the context):

```{r}
g <- (
  ggplot(plot_df, aes(x=row_number, y=.resid))
  + geom_point(alpha=0.6)
  
  + theme_bw()
  + geom_hline(yintercept = c(-2,2), color="red", linetype="dashed")
  + labs(title="Distribution of residuals (the closer to zero the better)")
)

g
```

#### Measure: Mean Absolute Error (MAE)

$$
MAE = \frac{\sum_{i=1}^{n}{|y_i - \hat{y}_i|}}{n}
$$

```{r}
plot_df %>% mae(Today, .pred)
```

#### Measure: Root Mean Squared Error (RMSE)

$$
RMSE = \frac{\sum_{i=1}^{n}{(y_i - \hat{y}_i)^2}}{n}
$$

```{r}
plot_df %>% rmse(Today, .pred)
```

:dart: **ACTION POINT**: Would a better model have a larger or smaller value of MAE/RMSE?

> your text goes here


### Step 3.3 Visualize the SVM decision space (Regression)

Now, let's **replicate** what we did in Step 1.3 only this time for the `Smarket` data and using predictions from the `smarket_tidymodel`.

We start by summarising the data. We want to find out the minimum and maximal values that the columns `Volumn` and `Lag1` reach: 

```{r}
filtered_data %>% 
    select(c(Volume, Lag1)) %>%
    summary()
```
Then, we create a simulated dataset with combinations of the `Volume` and `Lag1` columns:

```{r}
sim.data <- 
  crossing(Volume   = seq(0,3.5,0.1),
           Lag1 = seq(-5,6,0.2))
sim.data <- augment(smarket_tidymodel, sim.data)
head(sim.data)
```
:bulb: Look at the entire dataset with `View(sim.data)` 

Looking back at the plot of residuals, let's flag the worst predictions, those with an absolute residual above `2`.

```{r}
plot_df$residual_above_2 <- (plot_df$.resid) > 2
```


```{r, dpi=300}
g <- (
  plot_df %>%   
    ggplot()
  
    ## Tile the background of the plot with SVM predictions
    + geom_tile(data = sim.data, aes(x=Volume, y=Lag1, fill = .pred), alpha = 0.45)
  
    ## Actual data
    + geom_point(aes(x=Volume, y=Lag1, colour = residual_above_2, shape = residual_above_2, alpha=residual_above_2), size=2.5, stroke=0.95)
  
    ## Define X and Os
    + scale_shape_manual(values = c(4, 1))
    + scale_fill_viridis_c()
    + scale_color_manual(values=c("black", "red"))
    + scale_alpha_manual(values=c(0.1, 0.7))
    
    ## (OPTIONAL) Customizing the colours and theme of the plot
    + theme_minimal()
    + theme(panel.grid = element_blank(), legend.position = 'bottom', plot.title = element_text(hjust = 0.5))
    + labs(x = 'Volume', y = 'Lag 1', fill = "Today's Prediction", colour = 'Residual above 2?', shape = 'Residual above 2?', alpha='Residual above 2?', title='Worst predictions are marked as red circles')
)

g
```

:bulb: The plot above might not be as easy to understand as the one for classification. 

### Step 3.3: Understand the parameters of `svm_rbf`

The `svm_rbf` function has three parameters you can tune: 
- `cost`
- `rbf_sigma`
- `margin`

:dart: **ACTION POINT**: Train your abilities to interact with code documentation. Type `?svm_rbf` and hit ENTER. What do these parameters represent?

:bulb: Tip: At the bottom of the help page, you will find a link to `kernlab engine details` that has more useful info about SVM RBF.

> your text goes here


### Step 3.4: Tweak the parameters

:handshake: **WORKING TOGETHER** In pairs, change the values of `cost`, `rbf_sigma` and `margin` in the chunk below and run the other two chunks of code to look at the distribution of residuals and summary metrics. 

Discuss your findings. Can you find any combination of values that makes the model better? Or any that makes it worse?

```{r}
alternative_smarket_model <-
  svm_rbf(cost=1, rbf_sigma=10, margin=0.9) %>% 
  set_mode('regression') %>% 
  fit(Today ~ ., data = filtered_data)

alternative_smarket_model
```
**Residuals plot**

```{r, dpi=300}
plot_df <- 
  augment(alternative_smarket_model, filtered_data) %>% 
  mutate(row_number=row_number()) ## adding this here just to make our plot easier

g <- (
  ggplot(plot_df, aes(x=row_number, y=.resid))
  + geom_point(alpha=0.6)
  
  + theme_bw()
  + geom_hline(yintercept = c(-2,2), color="red")
)

g
```

**Metrics**

```{r}
## Use the vectorized version of MAE and RMSE functions
plot_df %>% summarise(mae=mae_vec(Today, .pred),
                      rmse=rmse_vec(Today, .pred))
```


#### :house: **Take-home exercise Q4:**

- Retrain the model in Step 3 for `Smarket`, this time using `svm_linear` instead of `svm_rbf`. 
- Reuse the code in Step 3.4 to replicate the plots and metric calculations for this new model.
- Which model fits the target variable (`Today`) better?

```{r}
# your code goes here
```

> your text goes here


</details>
<details><summary>**Want to take it to next level? (Optional)**</summary>

## Want to take it to next level? (Optional)

In a separate, more advanced, [bonus lab roadmap](/weeks/week08/lab_advanced.qmd) we show how to perform [k-fold cross-validation](/weeks/week04/lecture.html#the-cross-validation-setup) using `tidymodels` to tune the parameters of SVM automatically.

It is optional, you don't need to read it, but it might be the best way to solidify your knowledge of SVM and its parameters.

</details>

